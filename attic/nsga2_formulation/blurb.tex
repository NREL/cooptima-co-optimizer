\documentclass[review]{article}

\usepackage{lineno,hyperref}

\usepackage{algcompatible}
\usepackage{algorithm}
\usepackage{algorithmicx}
 \usepackage{amsfonts}
 \usepackage{float}
\usepackage{amsmath}
 \usepackage{arydshln}
 \usepackage{booktabs}
  \usepackage{multirow}
\modulolinenumbers[5]

\usepackage[total={6in, 8in}]{geometry}
\title{Coopt with Python DEAP Package for NSGA-II}
\author{\normalsize{Juli Mueller}}
\date{\normalsize{\today}}



\begin{document}
\maketitle

\noindent
To run the code: \textsf{python nsga2\_k.py}.\\



\noindent
Some more info:  I'm not going into too much detail of multi-objective optimization. If you want to know more, let me know. This here is just the bare minimum. Let me know if something is incoherent. \\
Formulate the problem as a bi-objective problem:
\begin{subequations}
\begin{equation}
\min_{\mathbf{x}}  [f_1(\mathbf{x}), f_2(\mathbf{x})]^T
\end{equation}
\begin{equation}
\text{such that } \sum_{i = 1}^d x_i = 1\label{eq:sumconst}
\end{equation}
\begin{equation}
x_i \in [0,1], i = 1, \ldots, d,
\end{equation}
\begin{equation}
f_1(\mathbf{x}) =  -\text{Merit}(\mathbf{x}) \label{eq:merit}
\end{equation}
\begin{equation}
f_2(\mathbf{x}) = \text{Cost}(\mathbf{x})
\end{equation}
\end{subequations}
where $\mathbf{x}=[x_1, \ldots, x_d]^T$ denotes the parameters to optimize,  $d=17$ is the number of parameters. Objective~(\ref{eq:merit}) minimizes the negative of the merit functions, i.e., we maximize the merit function. The merit function \textsf{mtf\_mmf} is defined in \textsf{merit\_functions.py}. I changed this function only by adding $K$ as an input argument (previously hard coded in here).\\

The objective functions are cheap to evaluate, so I used a multi-objective genetic algorithm to solve the problem. In particular, I downloaded the DEAP python package \url{https://pypi.python.org/pypi/deap} and adapted whatever I found in the online documentation to the code you gave me. I used the NSGA-II~\cite{Deb2000} option for evolving the population (consisting of individuals) over the generations (these are the iterations).  Initially, we uniformly select points $\mathbf{y}=[y_1, \ldots, y_d]^T$ from the whole parameter space and create the individuals after enforcing~(\ref{eq:sumconst}) which is done by dividing each point's parameters by the sum over the parameters, i.e., 
\begin{equation}
x_i = \frac{y_i}{\sum_{i=1}^d y_i} \ \forall i, \label{eq: forceone}
\end{equation}
see \textsf{uniform} lines 116ff.\\

Then the fitness function is evaluated (\textsf{eval\_mo}, merit and cost, lines 78ff) for each individual. We choose the best individuals of the current generation and mate and mutate them to generate offspring, i.e., the individuals for the next generation (``the fittest individuals survive'', good properties of parents are inherited by their children). When doing mutation and mating, we have to enforce~(\ref{eq:sumconst}), which is done as in~(\ref{eq: forceone}), see \textsf{scale} lines 122ff. We iterate over all generations and keep the non-dominated solutions (the ones on the Pareto front that is plotted to a pdf-file after the algorithm finishes).\\

Algorithms parameters are (lines 200-202):
\begin{itemize}
\item NGEN: the number of generations
\item MU: the number of individuals in each generation
\item CXPB: the cross-over probability (needed for generating offspring)
\end{itemize}
Thus, we do a total of NGEN $\times$ MU function evaluations. Changing the parameter values may influence the goodness of your results, but you can play with this. In the main function, \textsf{KVEC} (line 265) defines all the $K$ values that you want to run. Right now they are all being run, so out-comment or delete whatever you don't want. 




\bibliographystyle{plain}
\bibliography{refs}
\end{document}